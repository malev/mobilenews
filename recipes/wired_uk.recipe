
__license__   = 'GPL v3'
__copyright__ = '2010, Darko Miletic <darko.miletic at gmail.com>'
'''
www.wired.co.uk
'''

from calibre import strftime
from calibre.web.feeds.news import BasicNewsRecipe

class Wired_UK(BasicNewsRecipe):
    title                 = 'Wired Magazine - UK edition'
    __author__            = 'Darko Miletic'
    description           = 'Gaming news'
    publisher             = 'Conde Nast Digital'
    category              = 'news, games, IT, gadgets'
    oldest_article        = 32
    max_articles_per_feed = 100
    no_stylesheets        = True
    encoding              = 'utf-8'
    use_embedded_content  = False
    masthead_url          = 'http://www.wired.co.uk/_/media/wired-logo_UK.gif'
    language              = 'en_GB'
    extra_css             = ' body{font-family: Palatino,"Palatino Linotype","Times New Roman",Times,serif} img{margin-bottom: 0.8em } .img-descr{font-family: Tahoma,Arial,Helvetica,sans-serif; font-size: 0.6875em; display: block} '
    index                 = 'http://www.wired.co.uk/wired-magazine.aspx'

    conversion_options = {
                          'comment'   : description
                        , 'tags'      : category
                        , 'publisher' : publisher
                        , 'language'  : language
                        }

    keep_only_tags = [dict(name='div', attrs={'class':'article-box'})]
    remove_tags = [
                     dict(name=['object','embed','iframe','link'])
                    ,dict(attrs={'class':['opts','comment','stories']})
                  ]
    remove_tags_after = dict(name='div',attrs={'class':'stories'})
    remove_attributes = ['height','width']


    def parse_index(self):
        totalfeeds = []
        soup   = self.index_to_soup(self.index)
        maincontent = soup.find('div',attrs={'class':'main-content'})
        mfeed = []
        if maincontent:
           st = maincontent.find(attrs={'class':'most-wired-box'})
           if st:
              for itt in st.findAll('a',href=True):
               url   = 'http://www.wired.co.uk' + itt['href']
               title = self.tag_to_string(itt)
               description = ''
               date  = strftime(self.timefmt)
               mfeed.append({
                                  'title'      :title
                                 ,'date'       :date
                                 ,'url'        :url
                                 ,'description':description
                                })
        totalfeeds.append(('Articles', mfeed))
        return totalfeeds

    def get_cover_url(self):
        cover_url = None
        soup = self.index_to_soup(self.index)
        cover_item = soup.find('span', attrs={'class':'cover'})
        if cover_item:
           cover_url = cover_item.img['src']
        return cover_url

    def print_version(self, url):
        return url + '?page=all'
